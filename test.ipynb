{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbba6845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import redis\n",
    "r = redis.Redis(host='localhost', port=6379, decode_responses=True)\n",
    "print(r.ping())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7986fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad19070a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bar'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.set('foo', 'bar')\n",
    "# True\n",
    "r.get('foo')\n",
    "# bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9790308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Optional\n",
    "from datetime import datetime\n",
    "import json\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67f84964",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WorkingMemorySlot(Enum):\n",
    "    \"\"\"\n",
    "    Cognitive slots in working memory.\n",
    "    \n",
    "    Each slot represents a distinct type of information the agent\n",
    "    might hold in active cognition. The separation allows independent\n",
    "    access and update‚Äîchanging the current goal doesn't require\n",
    "    rewriting the entire working memory.\n",
    "    \"\"\"\n",
    "    CURRENT_GOAL = \"current_goal\"\n",
    "    ACTIVE_CONTEXT = \"active_context\"\n",
    "    SCRATCHPAD = \"scratchpad\"\n",
    "    RECENT_OBSERVATIONS = \"recent_observations\"\n",
    "    PENDING_ACTIONS = \"pending_actions\"\n",
    "    USER_INTENT = \"user_intent\"\n",
    "    REASONING_TRACE = \"reasoning_trace\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d1fb71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class WorkingMemoryEntry:\n",
    "    \"\"\"\n",
    "    A single entry in working memory.\n",
    "    \n",
    "    Each entry has content (what we're remembering), metadata (when, how important),\n",
    "    and lifecycle information (how long until it expires).\n",
    "    \"\"\"\n",
    "    slot: WorkingMemorySlot\n",
    "    content: Any  # JSON-serializable content\n",
    "    timestamp: datetime = field(default_factory=datetime.utcnow)\n",
    "    ttl_seconds: int = 300  # 5 minute default‚Äîtune based on your application\n",
    "    importance: float = 0.5  # 0-1 scale; higher = retain longer under pressure\n",
    "\n",
    "    def to_redis_hash(self) -> dict:\n",
    "        \"\"\"\n",
    "        Convert to Redis hash format.\n",
    "        \n",
    "        Redis hashes store field-value pairs. We serialize complex content\n",
    "        to JSON since Redis values are strings/bytes. This serialization\n",
    "        is intentionally simple‚Äîif you need more sophisticated serialization,\n",
    "        consider msgpack or protobuf for better performance.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"slot\": self.slot.value,\n",
    "            \"content\": json.dumps(self.content),\n",
    "            \"timestamp\": self.timestamp.isoformat(),\n",
    "            \"importance\": str(self.importance)\n",
    "        }\n",
    "    \n",
    "@classmethod\n",
    "def from_redis_hash(cls, data: dict) -> \"WorkingMemoryEntry\":\n",
    "    \"\"\"\n",
    "    Reconstruct from Redis hash data.\n",
    "    \n",
    "    Note the byte decoding‚ÄîRedis returns bytes by default.\n",
    "    \"\"\"\n",
    "    return cls(\n",
    "        slot=WorkingMemorySlot(data[b\"slot\"].decode()),\n",
    "        content=json.loads(data[b\"content\"].decode()),\n",
    "        timestamp=datetime.fromisoformat(data[b\"timestamp\"].decode()),\n",
    "        importance=float(data[b\"importance\"].decode()),\n",
    "        ttl_seconds=0  # Already in Redis; TTL managed there\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99a56ad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: redis[hiredis] in c:\\users\\sashi\\anaconda3\\envs\\layered\\lib\\site-packages (7.1.0)\n",
      "Requirement already satisfied: async-timeout>=4.0.3 in c:\\users\\sashi\\anaconda3\\envs\\layered\\lib\\site-packages (from redis[hiredis]) (5.0.1)\n",
      "Collecting hiredis>=3.2.0 (from redis[hiredis])\n",
      "  Downloading hiredis-3.3.0-cp311-cp311-win_amd64.whl.metadata (7.7 kB)\n",
      "Downloading hiredis-3.3.0-cp311-cp311-win_amd64.whl (22 kB)\n",
      "Installing collected packages: hiredis\n",
      "Successfully installed hiredis-3.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install redis[hiredis]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac47533",
   "metadata": {},
   "source": [
    "pip install hiredis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96b0d92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis.asyncio as redis\n",
    "class WorkingMemoryManager:\n",
    "    \"\"\"\n",
    "    Manages ephemeral cognitive state with automatic decay.\n",
    "    \n",
    "    This class is the agent's interface to its working memory. It handles\n",
    "    all the complexity of Redis operations, key management, and TTL handling,\n",
    "    exposing a simple API for reading and writing cognitive state.\n",
    "    \n",
    "    Design Principles:\n",
    "    1. Fast access (<1ms) for active reasoning‚Äîno operation should block\n",
    "    2. Automatic cleanup via TTL‚Äîno manual garbage collection needed\n",
    "    3. Importance-weighted retention during overflow‚Äîsmart degradation\n",
    "    4. Session isolation for multi-tenant deployments‚Äîusers don't see each other's state\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        redis_client: redis.Redis,\n",
    "        session_id: str,\n",
    "        max_observations: int = 10,\n",
    "        default_ttl: int = 300\n",
    "    ):\n",
    "        self.redis = redis_client\n",
    "        self.session_id = session_id\n",
    "        self.max_observations = max_observations\n",
    "        self.default_ttl = default_ttl\n",
    "        self._key_prefix = f\"wm:{session_id}\"\n",
    "    async def _slot_key(self, slot: WorkingMemorySlot) -> str:\n",
    "        \"\"\"\n",
    "        Generate Redis key for a memory slot.\n",
    "        \n",
    "        Key structure: wm:{session_id}:{slot_name}\n",
    "        \n",
    "        This hierarchical naming enables:\n",
    "        - Easy debugging (keys are human-readable)\n",
    "        - Pattern-based operations (delete all slots for a session)\n",
    "        - Clear ownership (each session has its own namespace)\n",
    "        \"\"\"\n",
    "        return f\"{self._key_prefix}:{slot.value}\"\n",
    "    async def set_slot(\n",
    "        self,\n",
    "        slot: WorkingMemorySlot,\n",
    "        content: Any,\n",
    "        ttl_seconds: Optional[int] = None,\n",
    "        importance: float = 0.5\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Store content in a working memory slot.\n",
    "        \n",
    "        This is the primary write operation. It overwrites any existing\n",
    "        content in the slot‚Äîthere's no append or merge, by design.\n",
    "        Working memory slots hold current state, not history.\n",
    "        \n",
    "        Args:\n",
    "            slot: The cognitive slot to update\n",
    "            content: Any JSON-serializable content\n",
    "            ttl_seconds: Override default TTL (useful for high-importance content)\n",
    "            importance: 0-1 score for retention priority during pressure\n",
    "        \"\"\"\n",
    "        entry = WorkingMemoryEntry(\n",
    "            slot=slot,\n",
    "            content=content,\n",
    "            ttl_seconds=ttl_seconds or self.default_ttl,\n",
    "            importance=importance\n",
    "        )\n",
    "        \n",
    "        key = self._slot_key(slot)\n",
    "        \n",
    "        # Use pipeline for atomic operation\n",
    "        async with self.redis.pipeline(transaction=True) as pipe:\n",
    "            await pipe.hset(key, mapping=entry.to_redis_hash())\n",
    "            await pipe.expire(key, entry.ttl_seconds)\n",
    "            await pipe.execute()\n",
    "    def get_slot(self, slot: WorkingMemorySlot) -> Optional[WorkingMemoryEntry]:\n",
    "        \"\"\"\n",
    "        Retrieve content from a working memory slot.\n",
    "        \n",
    "        Returns None if the slot is empty or expired. This is intentional‚Äî\n",
    "        we treat expired content the same as never-existed content.\n",
    "        The caller doesn't need to distinguish between \"was never set\"\n",
    "        and \"was set but expired.\"\n",
    "        \"\"\"\n",
    "        key = self._slot_key(slot)\n",
    "        data = self.redis.hgetall(key)\n",
    "        \n",
    "        if not data:\n",
    "            return None\n",
    "        \n",
    "        return WorkingMemoryEntry.from_redis_hash(data)\n",
    "    async def append_observation(self, observation: dict) -> None:\n",
    "        \"\"\"\n",
    "        Add an observation to the recent observations list.\n",
    "        \n",
    "        Observations are different from slot content. Slots hold single values\n",
    "        that get overwritten. Observations accumulate‚Äîthe agent notices things\n",
    "        over time, and we want to keep a sliding window of recent notices.\n",
    "        \n",
    "        We use a Redis sorted set with timestamps as scores. This gives us:\n",
    "        - Automatic ordering by time\n",
    "        - Efficient retrieval of most recent N items\n",
    "        - Easy trimming of old items\n",
    "        \n",
    "        The timestamp-as-score pattern is powerful: it lets us query time\n",
    "        ranges efficiently, which we'd need if we wanted \"observations from\n",
    "        the last 5 minutes\" rather than just \"last N observations.\"\n",
    "        \"\"\"\n",
    "        key = f\"{self._key_prefix}:observations\"\n",
    "        timestamp = datetime.utcnow().timestamp()\n",
    "        \n",
    "        async with self.redis.pipeline(self, transaction=True) as pipe:\n",
    "            # Add new observation with timestamp score\n",
    "            await pipe.zadd(key, {json.dumps(observation): timestamp})\n",
    "            \n",
    "            # Trim to max size, keeping most recent\n",
    "            # ZREMRANGEBYRANK removes elements by rank (0 = lowest score = oldest)\n",
    "            # We keep from -(max+1) to -1 (the most recent max_observations)\n",
    "            await pipe.zremrangebyrank(key, 0, -(self.max_observations + 1))\n",
    "            \n",
    "            # Set expiry on the whole set\n",
    "            # Even if we don't add new observations, old ones eventually vanish\n",
    "            await pipe.expire(key, self.default_ttl * 2)\n",
    "            \n",
    "            await pipe.execute()\n",
    "    async def get_recent_observations(self, limit: int = 5) -> list[dict]:\n",
    "        \"\"\"\n",
    "        Retrieve most recent observations in chronological order.\n",
    "        \n",
    "        Returns observations oldest-first within the result set. This ordering\n",
    "        matches how humans typically review history‚Äîstart from earlier and\n",
    "        read toward now.\n",
    "        \"\"\"\n",
    "        key = f\"{self._key_prefix}:observations\"\n",
    "        \n",
    "        # ZRANGE with negative indices gets from the end (most recent)\n",
    "        # -limit to -1 gives us the last `limit` items, oldest-first\n",
    "        observations = await self.redis.zrange(key, -limit, -1)\n",
    "        \n",
    "        return [json.loads(obs.decode()) for obs in observations]\n",
    "    async def get_full_context(self) -> dict:\n",
    "        \"\"\"\n",
    "        Retrieve complete working memory state.\n",
    "        \n",
    "        This is the primary method called during context assembly. It gathers\n",
    "        all slots, observations, and scratchpad into a single dictionary\n",
    "        suitable for inclusion in an LLM prompt.\n",
    "        \n",
    "        The returned structure mirrors our cognitive model:\n",
    "        - Named slots with their current values\n",
    "        - Recent observations as a list\n",
    "        - Scratchpad as a key-value store\n",
    "        \n",
    "        Empty/expired slots are simply absent from the result‚Äîno need for\n",
    "        the caller to handle None values.\n",
    "        \"\"\"\n",
    "        context = {}\n",
    "        \n",
    "        # Gather all standard slots\n",
    "        for slot in WorkingMemorySlot:\n",
    "            entry = await self.get_slot(slot)\n",
    "            if entry:\n",
    "                context[slot.value] = entry.content\n",
    "        \n",
    "        # Add observations\n",
    "        context[\"recent_observations\"] = await self.get_recent_observations()\n",
    "        \n",
    "        # Add scratchpad\n",
    "        context[\"scratchpad\"] = await self.get_scratchpad()\n",
    "        \n",
    "        return context\n",
    "    \n",
    "    async def agent_reasoning_step(wm: WorkingMemoryManager, user_input: str, llm: Any) -> str:\n",
    "        \"\"\"\n",
    "        Execute one step of agent reasoning with working memory.\n",
    "        \n",
    "        This function demonstrates the typical flow:\n",
    "        1. Load existing working memory context\n",
    "        2. Update working memory with new input\n",
    "        3. Generate response using full context\n",
    "        4. Record results back to working memory\n",
    "        \"\"\"\n",
    "    \n",
    "    # 1. Load current working memory context\n",
    "    # This gives us everything the agent currently \"knows\" about the session\n",
    "        context = await wm.get_full_context()\n",
    "    \n",
    "    # 2. Update with new input\n",
    "    # The user's intent is high-importance‚Äîwe want to retain it\n",
    "        await wm.set_slot(\n",
    "            WorkingMemorySlot.USER_INTENT,\n",
    "            {\n",
    "                \"raw_input\": user_input,\n",
    "                \"parsed_at\": datetime.utcnow().isoformat()\n",
    "            },\n",
    "            importance=0.9  # High importance for user intent\n",
    "        )\n",
    "    \n",
    "    # 3. Record as an observation\n",
    "    # This goes into the observation stream for temporal tracking\n",
    "        await wm.append_observation({\n",
    "            \"type\": \"user_input\",\n",
    "            \"content\": user_input,\n",
    "            \"timestamp\": datetime.utcnow().isoformat()\n",
    "        })\n",
    "        \n",
    "    # 4. Generate response with full context\n",
    "    # The context dict includes all working memory state\n",
    "        response = await llm.generate(\n",
    "            prompt=build_prompt(user_input, context)\n",
    "        )\n",
    "        \n",
    "    # 5. Update reasoning trace\n",
    "    # Track what we've done for future reference\n",
    "        await wm.update_scratchpad(\"last_response\", response)\n",
    "        \n",
    "        reasoning_steps = context.get(\"scratchpad\", {}).get(\"reasoning_steps\", [])\n",
    "        reasoning_steps.append({\n",
    "            \"input\": user_input,\n",
    "            \"output\": response,\n",
    "            \"timestamp\": datetime.utcnow().isoformat()\n",
    "        })\n",
    "        await wm.update_scratchpad(\"reasoning_steps\", reasoning_steps)\n",
    "        \n",
    "        return response\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad9713f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "adda3fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "REDIS_URL = \"redis://localhost:6379\"\n",
    "redis_client = redis.from_url(REDIS_URL, decode_responses=True)\n",
    "# =============================================================================\n",
    "# PART 1: WORKING MEMORY (Redis)\n",
    "# =============================================================================\n",
    "# Working memory is like your mental scratchpad - it holds what you're \n",
    "# currently thinking about and expires automatically.\n",
    "\n",
    "def working_memory_set(session_id: str, key: str, value: dict, ttl: int = 300):\n",
    "    \"\"\"\n",
    "    Store something in working memory.\n",
    "    \n",
    "    Args:\n",
    "        session_id: Unique session identifier\n",
    "        key: What we're storing (e.g., \"current_goal\", \"user_intent\")\n",
    "        value: The data to store\n",
    "        ttl: Time-to-live in seconds (default 5 minutes)\n",
    "    \"\"\"\n",
    "    redis_key = f\"wm:{session_id}:{key}\"\n",
    "    redis_client.setex(redis_key, ttl, json.dumps(value))\n",
    "\n",
    "\n",
    "def working_memory_get(session_id: str, key: str) -> dict | None:\n",
    "    \"\"\"Retrieve something from working memory.\"\"\"\n",
    "    redis_key = f\"wm:{session_id}:{key}\"\n",
    "    data = redis_client.get(redis_key)\n",
    "    return json.loads(data) if data else None\n",
    "\n",
    "\n",
    "def working_memory_add_observation(session_id: str, observation: dict, max_items: int = 10):\n",
    "    \"\"\"\n",
    "    Add an observation to the observation stream.\n",
    "    Uses a Redis list to maintain ordered observations.\n",
    "    \"\"\"\n",
    "    redis_key = f\"wm:{session_id}:observations\"\n",
    "    observation[\"timestamp\"] = datetime.utcnow().isoformat()\n",
    "    \n",
    "    redis_client.lpush(redis_key, json.dumps(observation))\n",
    "    redis_client.ltrim(redis_key, 0, max_items - 1)  # Keep only recent items\n",
    "    redis_client.expire(redis_key, 600)  # Expire after 10 minutes\n",
    "\n",
    "\n",
    "def working_memory_get_observations(session_id: str, limit: int = 5) -> list:\n",
    "    \"\"\"Get recent observations.\"\"\"\n",
    "    redis_key = f\"wm:{session_id}:observations\"\n",
    "    items = redis_client.lrange(redis_key, 0, limit - 1)\n",
    "    return [json.loads(item) for item in items]\n",
    "\n",
    "\n",
    "def working_memory_get_full_context(session_id: str) -> dict:\n",
    "    \"\"\"Get all working memory for a session.\"\"\"\n",
    "    context = {}\n",
    "    \n",
    "    # Get all keys for this session\n",
    "    pattern = f\"wm:{session_id}:*\"\n",
    "    for key in redis_client.scan_iter(match=pattern):\n",
    "        short_key = key.split(\":\")[-1]\n",
    "        if short_key == \"observations\":\n",
    "            context[\"observations\"] = working_memory_get_observations(session_id)\n",
    "        else:\n",
    "            context[short_key] = working_memory_get(session_id, short_key)\n",
    "    \n",
    "    return context\n",
    "\n",
    "\n",
    "def demo_working_memory():\n",
    "    \"\"\"Demonstrate working memory operations.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìù WORKING MEMORY (Redis)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    session_id = f\"demo_{uuid4().hex[:8]}\"\n",
    "    \n",
    "    # Set current goal\n",
    "    working_memory_set(session_id, \"current_goal\", {\n",
    "        \"goal\": \"Help user analyze sales data\",\n",
    "        \"priority\": \"high\"\n",
    "    })\n",
    "    print(\"‚úì Set current goal\")\n",
    "    \n",
    "    # Set user intent\n",
    "    working_memory_set(session_id, \"user_intent\", {\n",
    "        \"intent\": \"data_analysis\",\n",
    "        \"confidence\": 0.9\n",
    "    })\n",
    "    print(\"‚úì Set user intent\")\n",
    "    \n",
    "    # Add some observations\n",
    "    working_memory_add_observation(session_id, {\"type\": \"user_upload\", \"file\": \"sales.csv\"})\n",
    "    working_memory_add_observation(session_id, {\"type\": \"user_question\", \"text\": \"Show me trends\"})\n",
    "    print(\"‚úì Added observations\")\n",
    "    \n",
    "    # Retrieve everything\n",
    "    context = working_memory_get_full_context(session_id)\n",
    "    print(f\"\\nüìã Full Working Memory Context:\")\n",
    "    print(json.dumps(context, indent=2))\n",
    "    \n",
    "    # Show TTL\n",
    "    ttl = redis_client.ttl(f\"wm:{session_id}:current_goal\")\n",
    "    print(f\"\\n‚è∞ TTL remaining: {ttl} seconds (auto-expires!)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "29382788",
   "metadata": {},
   "outputs": [],
   "source": [
    "wmm = WorkingMemoryManager(redis_client=redis.Redis, session_id=\"session123\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e04da4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìù WORKING MEMORY (Redis)\n",
      "============================================================\n",
      "‚úì Set current goal\n",
      "‚úì Set user intent\n",
      "‚úì Added observations\n",
      "\n",
      "üìã Full Working Memory Context:\n",
      "{\n",
      "  \"user_intent\": {\n",
      "    \"intent\": \"data_analysis\",\n",
      "    \"confidence\": 0.9\n",
      "  },\n",
      "  \"observations\": [\n",
      "    {\n",
      "      \"type\": \"user_question\",\n",
      "      \"text\": \"Show me trends\",\n",
      "      \"timestamp\": \"2025-12-19T15:45:58.873735\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"user_upload\",\n",
      "      \"file\": \"sales.csv\",\n",
      "      \"timestamp\": \"2025-12-19T15:45:58.867905\"\n",
      "    }\n",
      "  ],\n",
      "  \"current_goal\": {\n",
      "    \"goal\": \"Help user analyze sales data\",\n",
      "    \"priority\": \"high\"\n",
      "  }\n",
      "}\n",
      "\n",
      "‚è∞ TTL remaining: 300 seconds (auto-expires!)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pavan VK Alapati\\AppData\\Local\\Temp\\ipykernel_29184\\2671665877.py:44: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  observation[\"timestamp\"] = datetime.utcnow().isoformat()\n"
     ]
    }
   ],
   "source": [
    "demo_working_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c874b04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymongo\n",
      "  Downloading pymongo-4.15.5-cp311-cp311-win_amd64.whl.metadata (22 kB)\n",
      "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
      "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Downloading pymongo-4.15.5-cp311-cp311-win_amd64.whl (859 kB)\n",
      "   ---------------------------------------- 0.0/859.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 859.2/859.2 kB 9.6 MB/s  0:00:00\n",
      "Downloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
      "Installing collected packages: dnspython, pymongo\n",
      "\n",
      "   ---------------------------------------- 0/2 [dnspython]\n",
      "   ---------------------------------------- 0/2 [dnspython]\n",
      "   ---------------------------------------- 0/2 [dnspython]\n",
      "   ---------------------------------------- 0/2 [dnspython]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   -------------------- ------------------- 1/2 [pymongo]\n",
      "   ---------------------------------------- 2/2 [pymongo]\n",
      "\n",
      "Successfully installed dnspython-2.8.0 pymongo-4.15.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdce952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23649ec7",
   "metadata": {},
   "source": [
    "# MONGO DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb43b004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "\n",
    "myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "\n",
    "mydb = myclient[\"mydatabase\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e56fb2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['admin', 'config', 'local']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myclient.list_database_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85383548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting qdrant-client\n",
      "  Downloading qdrant_client-1.16.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: pymongo in c:\\users\\sashi\\anaconda3\\envs\\layered\\lib\\site-packages (4.15.5)\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.2.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting langgraph\n",
      "  Downloading langgraph-1.0.5-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting torch\n",
      "  Downloading torch-2.9.1-cp311-cp311-win_amd64.whl.metadata (30 kB)\n",
      "Collecting grpcio>=1.41.0 (from qdrant-client)\n",
      "  Downloading grpcio-1.76.0-cp311-cp311-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting httpx>=0.20.0 (from httpx[http2]>=0.20.0->qdrant-client)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting numpy>=1.21 (from qdrant-client)\n",
      "  Downloading numpy-2.4.0-cp311-cp311-win_amd64.whl.metadata (6.6 kB)\n",
      "Collecting portalocker<4.0,>=2.7.0 (from qdrant-client)\n",
      "  Using cached portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting protobuf>=3.20.0 (from qdrant-client)\n",
      "  Downloading protobuf-6.33.2-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8 (from qdrant-client)\n",
      "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Collecting urllib3<3,>=1.26.14 (from qdrant-client)\n",
      "  Downloading urllib3-2.6.2-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\sashi\\anaconda3\\envs\\layered\\lib\\site-packages (from portalocker<4.0,>=2.7.0->qdrant-client) (311)\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in c:\\users\\sashi\\anaconda3\\envs\\layered\\lib\\site-packages (from pymongo) (2.8.0)\n",
      "Collecting transformers<6.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.57.3-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting tqdm (from sentence-transformers)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Downloading scikit_learn-1.8.0-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Downloading scipy-1.16.3-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-1.2.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\sashi\\anaconda3\\envs\\layered\\lib\\site-packages (from sentence-transformers) (4.15.0)\n",
      "Collecting filelock (from transformers<6.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading filelock-3.20.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Using cached huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\sashi\\anaconda3\\envs\\layered\\lib\\site-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers<6.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading pyyaml-6.0.3-cp311-cp311-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers<6.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading regex-2025.11.3-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "Collecting requests (from transformers<6.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers<6.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached tokenizers-0.22.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<6.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading fsspec-2025.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting langchain-core>=0.1 (from langgraph)\n",
      "  Downloading langchain_core-1.2.5-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting langgraph-checkpoint<4.0.0,>=2.1.0 (from langgraph)\n",
      "  Using cached langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting langgraph-prebuilt<1.1.0,>=1.0.2 (from langgraph)\n",
      "  Downloading langgraph_prebuilt-1.0.5-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting langgraph-sdk<0.4.0,>=0.3.0 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.3.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting xxhash>=3.5.0 (from langgraph)\n",
      "  Downloading xxhash-3.6.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting ormsgpack>=1.12.0 (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph)\n",
      "  Downloading ormsgpack-1.12.1-cp311-cp311-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting orjson>=3.10.1 (from langgraph-sdk<0.4.0,>=0.3.0->langgraph)\n",
      "  Downloading orjson-3.11.5-cp311-cp311-win_amd64.whl.metadata (42 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch)\n",
      "  Downloading networkx-3.6.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting anyio (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client)\n",
      "  Downloading anyio-4.12.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting certifi (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client)\n",
      "  Using cached certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting h2<5,>=3 (from httpx[http2]>=0.20.0->qdrant-client)\n",
      "  Using cached h2-4.3.0-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting hyperframe<7,>=6.1 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client)\n",
      "  Using cached hyperframe-6.1.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting hpack<5,>=4.1 (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client)\n",
      "  Using cached hpack-4.1.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting jsonpatch<2.0.0,>=1.33.0 (from langchain-core>=0.1->langgraph)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<1.0.0,>=0.3.45 (from langchain-core>=0.1->langgraph)\n",
      "  Downloading langsmith-0.5.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core>=0.1->langgraph)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting uuid-utils<1.0,>=0.12.0 (from langchain-core>=0.1->langgraph)\n",
      "  Downloading uuid_utils-0.12.0-cp39-abi3-win_amd64.whl.metadata (1.1 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0.0,>=1.33.0->langchain-core>=0.1->langgraph)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard>=0.23.0 (from langsmith<1.0.0,>=0.3.45->langchain-core>=0.1->langgraph)\n",
      "  Downloading zstandard-0.25.0-cp311-cp311-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client)\n",
      "  Downloading pydantic_core-2.41.5-cp311-cp311-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typing-inspection>=0.4.2 (from pydantic!=2.0.*,!=2.1.*,!=2.2.0,>=1.10.8->qdrant-client)\n",
      "  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->transformers<6.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading charset_normalizer-3.4.4-cp311-cp311-win_amd64.whl.metadata (38 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\sashi\\anaconda3\\envs\\layered\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Downloading markupsafe-3.0.3-cp311-cp311-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting joblib>=1.3.0 (from scikit-learn->sentence-transformers)\n",
      "  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting threadpoolctl>=3.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading qdrant_client-1.16.2-py3-none-any.whl (377 kB)\n",
      "Using cached portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
      "Downloading urllib3-2.6.2-py3-none-any.whl (131 kB)\n",
      "Downloading sentence_transformers-5.2.0-py3-none-any.whl (493 kB)\n",
      "Downloading transformers-4.57.3-py3-none-any.whl (12.0 MB)\n",
      "   ---------------------------------------- 0.0/12.0 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 2.6/12.0 MB 12.6 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 5.2/12.0 MB 12.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.4/12.0 MB 13.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.7/12.0 MB 12.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.0/12.0 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.0/12.0 MB 10.0 MB/s  0:00:01\n",
      "Using cached huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\n",
      "Using cached tokenizers-0.22.1-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "Downloading langgraph-1.0.5-py3-none-any.whl (157 kB)\n",
      "Using cached langgraph_checkpoint-3.0.1-py3-none-any.whl (46 kB)\n",
      "Downloading langgraph_prebuilt-1.0.5-py3-none-any.whl (35 kB)\n",
      "Downloading langgraph_sdk-0.3.1-py3-none-any.whl (66 kB)\n",
      "Downloading torch-2.9.1-cp311-cp311-win_amd64.whl (111.0 MB)\n",
      "   ---------------------------------------- 0.0/111.0 MB ? eta -:--:--\n",
      "    --------------------------------------- 2.6/111.0 MB 12.6 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 5.8/111.0 MB 13.6 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 8.1/111.0 MB 12.6 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 11.0/111.0 MB 12.7 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 13.9/111.0 MB 13.0 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 17.0/111.0 MB 13.1 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 20.2/111.0 MB 13.6 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 23.9/111.0 MB 14.0 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 27.0/111.0 MB 14.0 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 30.1/111.0 MB 14.1 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 32.5/111.0 MB 13.8 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 34.1/111.0 MB 13.7 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 34.6/111.0 MB 12.6 MB/s eta 0:00:07\n",
      "   ------------- -------------------------- 36.7/111.0 MB 12.1 MB/s eta 0:00:07\n",
      "   -------------- ------------------------- 39.1/111.0 MB 12.2 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 41.2/111.0 MB 12.0 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 43.5/111.0 MB 11.9 MB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 46.4/111.0 MB 12.0 MB/s eta 0:00:06\n",
      "   ----------------- ---------------------- 49.0/111.0 MB 12.0 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 51.4/111.0 MB 12.0 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 54.3/111.0 MB 12.1 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 56.9/111.0 MB 12.1 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 59.5/111.0 MB 12.1 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 61.6/111.0 MB 12.0 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 62.4/111.0 MB 11.7 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 62.4/111.0 MB 11.7 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 64.0/111.0 MB 11.0 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 66.1/111.0 MB 11.0 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 68.4/111.0 MB 11.0 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 70.8/111.0 MB 11.0 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 72.6/111.0 MB 10.9 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 74.4/111.0 MB 10.9 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 76.0/111.0 MB 10.8 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 78.9/111.0 MB 10.8 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 81.3/111.0 MB 10.9 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 84.7/111.0 MB 11.0 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 88.1/111.0 MB 11.1 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 91.5/111.0 MB 11.2 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 93.6/111.0 MB 11.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 96.2/111.0 MB 11.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 98.3/111.0 MB 11.2 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 100.9/111.0 MB 11.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 103.3/111.0 MB 11.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 104.3/111.0 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 105.9/111.0 MB 11.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 107.2/111.0 MB 10.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  109.1/111.0 MB 10.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  110.1/111.0 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  110.9/111.0 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  110.9/111.0 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 111.0/111.0 MB 10.1 MB/s  0:00:10\n",
      "Downloading fsspec-2025.12.0-py3-none-any.whl (201 kB)\n",
      "Downloading grpcio-1.76.0-cp311-cp311-win_amd64.whl (4.7 MB)\n",
      "   ---------------------------------------- 0.0/4.7 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 1.6/4.7 MB 8.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 2.4/4.7 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 3.7/4.7 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.7/4.7 MB 5.5 MB/s  0:00:00\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached h2-4.3.0-py3-none-any.whl (61 kB)\n",
      "Using cached hpack-4.1.0-py3-none-any.whl (34 kB)\n",
      "Using cached hyperframe-6.1.0-py3-none-any.whl (13 kB)\n",
      "Downloading langchain_core-1.2.5-py3-none-any.whl (484 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langsmith-0.5.0-py3-none-any.whl (273 kB)\n",
      "Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp311-cp311-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ------------------------------- -------- 1.6/2.0 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 5.9 MB/s  0:00:00\n",
      "Downloading pyyaml-6.0.3-cp311-cp311-win_amd64.whl (158 kB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading uuid_utils-0.12.0-cp39-abi3-win_amd64.whl (183 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading networkx-3.6.1-py3-none-any.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ------------------------------ --------- 1.6/2.1 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 6.1 MB/s  0:00:00\n",
      "Downloading numpy-2.4.0-cp311-cp311-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 2.9/12.6 MB 12.9 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 5.8/12.6 MB 13.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 8.4/12.6 MB 13.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.0/12.6 MB 12.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 11.4 MB/s  0:00:01\n",
      "Downloading orjson-3.11.5-cp311-cp311-win_amd64.whl (133 kB)\n",
      "Downloading ormsgpack-1.12.1-cp311-cp311-win_amd64.whl (115 kB)\n",
      "Downloading protobuf-6.33.2-cp310-abi3-win_amd64.whl (436 kB)\n",
      "Downloading regex-2025.11.3-cp311-cp311-win_amd64.whl (277 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp311-cp311-win_amd64.whl (106 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading safetensors-0.7.0-cp38-abi3-win_amd64.whl (341 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading xxhash-3.6.0-cp311-cp311-win_amd64.whl (31 kB)\n",
      "Downloading zstandard-0.25.0-cp311-cp311-win_amd64.whl (506 kB)\n",
      "Downloading anyio-4.12.0-py3-none-any.whl (113 kB)\n",
      "Downloading filelock-3.20.1-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading markupsafe-3.0.3-cp311-cp311-win_amd64.whl (15 kB)\n",
      "Downloading scikit_learn-1.8.0-cp311-cp311-win_amd64.whl (8.1 MB)\n",
      "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 1.0/8.1 MB 4.6 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 3.9/8.1 MB 10.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 6.8/8.1 MB 10.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.1/8.1 MB 10.0 MB/s  0:00:00\n",
      "Downloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Downloading scipy-1.16.3-cp311-cp311-win_amd64.whl (38.7 MB)\n",
      "   ---------------------------------------- 0.0/38.7 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 2.4/38.7 MB 12.3 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 5.0/38.7 MB 12.6 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 7.3/38.7 MB 11.9 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 10.5/38.7 MB 12.3 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 12.6/38.7 MB 12.7 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 13.1/38.7 MB 11.6 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 13.1/38.7 MB 11.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 15.2/38.7 MB 8.7 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 17.3/38.7 MB 8.9 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 19.1/38.7 MB 8.8 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 21.2/38.7 MB 9.0 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 23.6/38.7 MB 9.0 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 25.4/38.7 MB 9.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 27.0/38.7 MB 8.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 29.1/38.7 MB 9.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 30.9/38.7 MB 9.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 33.0/38.7 MB 9.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 36.2/38.7 MB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.5/38.7 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 38.7/38.7 MB 9.0 MB/s  0:00:04\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: mpmath, zstandard, xxhash, uuid-utils, urllib3, typing-inspection, tqdm, threadpoolctl, tenacity, sympy, safetensors, regex, pyyaml, pydantic-core, protobuf, portalocker, ormsgpack, orjson, numpy, networkx, MarkupSafe, jsonpointer, joblib, idna, hyperframe, hpack, h11, grpcio, fsspec, filelock, charset_normalizer, certifi, annotated-types, scipy, requests, pydantic, jsonpatch, jinja2, httpcore, h2, anyio, torch, scikit-learn, requests-toolbelt, huggingface-hub, httpx, tokenizers, langsmith, langgraph-sdk, transformers, qdrant-client, langchain-core, sentence-transformers, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
      "\n",
      "   ----------------------------------------  0/56 [mpmath]\n",
      "   ----------------------------------------  0/56 [mpmath]\n",
      "   ----------------------------------------  0/56 [mpmath]\n",
      "   ----------------------------------------  0/56 [mpmath]\n",
      "   ----------------------------------------  0/56 [mpmath]\n",
      "   ----------------------------------------  0/56 [mpmath]\n",
      "   ----------------------------------------  0/56 [mpmath]\n",
      "   ----------------------------------------  0/56 [mpmath]\n",
      "   ----------------------------------------  0/56 [mpmath]\n",
      "   ----------------------------------------  0/56 [mpmath]\n",
      "    ---------------------------------------  1/56 [zstandard]\n",
      "   -- -------------------------------------  3/56 [uuid-utils]\n",
      "   -- -------------------------------------  4/56 [urllib3]\n",
      "   -- -------------------------------------  4/56 [urllib3]\n",
      "   --- ------------------------------------  5/56 [typing-inspection]\n",
      "   ---- -----------------------------------  6/56 [tqdm]\n",
      "   ---- -----------------------------------  6/56 [tqdm]\n",
      "   ----- ----------------------------------  8/56 [tenacity]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------ ---------------------------------  9/56 [sympy]\n",
      "   ------- -------------------------------- 10/56 [safetensors]\n",
      "   ------- -------------------------------- 11/56 [regex]\n",
      "   ------- -------------------------------- 11/56 [regex]\n",
      "   ------- -------------------------------- 11/56 [regex]\n",
      "   -------- ------------------------------- 12/56 [pyyaml]\n",
      "   --------- ------------------------------ 13/56 [pydantic-core]\n",
      "   --------- ------------------------------ 13/56 [pydantic-core]\n",
      "   ---------- ----------------------------- 14/56 [protobuf]\n",
      "   ---------- ----------------------------- 14/56 [protobuf]\n",
      "   ---------- ----------------------------- 14/56 [protobuf]\n",
      "   ---------- ----------------------------- 14/56 [protobuf]\n",
      "   ---------- ----------------------------- 14/56 [protobuf]\n",
      "   ---------- ----------------------------- 14/56 [protobuf]\n",
      "   ---------- ----------------------------- 15/56 [portalocker]\n",
      "   ------------ --------------------------- 17/56 [orjson]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------ --------------------------- 18/56 [numpy]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   ------------- -------------------------- 19/56 [networkx]\n",
      "   -------------- ------------------------- 20/56 [MarkupSafe]\n",
      "   --------------- ------------------------ 22/56 [joblib]\n",
      "   --------------- ------------------------ 22/56 [joblib]\n",
      "   --------------- ------------------------ 22/56 [joblib]\n",
      "   --------------- ------------------------ 22/56 [joblib]\n",
      "   --------------- ------------------------ 22/56 [joblib]\n",
      "   --------------- ------------------------ 22/56 [joblib]\n",
      "   --------------- ------------------------ 22/56 [joblib]\n",
      "   ---------------- ----------------------- 23/56 [idna]\n",
      "   ---------------- ----------------------- 23/56 [idna]\n",
      "   ---------------- ----------------------- 23/56 [idna]\n",
      "   ----------------- ---------------------- 24/56 [hyperframe]\n",
      "   ----------------- ---------------------- 25/56 [hpack]\n",
      "   ------------------ --------------------- 26/56 [h11]\n",
      "   ------------------- -------------------- 27/56 [grpcio]\n",
      "   ------------------- -------------------- 27/56 [grpcio]\n",
      "   ------------------- -------------------- 27/56 [grpcio]\n",
      "   ------------------- -------------------- 27/56 [grpcio]\n",
      "   ------------------- -------------------- 27/56 [grpcio]\n",
      "   ------------------- -------------------- 27/56 [grpcio]\n",
      "   -------------------- ------------------- 28/56 [fsspec]\n",
      "   -------------------- ------------------- 28/56 [fsspec]\n",
      "   -------------------- ------------------- 28/56 [fsspec]\n",
      "   -------------------- ------------------- 28/56 [fsspec]\n",
      "   --------------------- ------------------ 30/56 [charset_normalizer]\n",
      "   ---------------------- ----------------- 32/56 [annotated-types]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ----------------------- ---------------- 33/56 [scipy]\n",
      "   ------------------------ --------------- 34/56 [requests]\n",
      "   ------------------------- -------------- 35/56 [pydantic]\n",
      "   ------------------------- -------------- 35/56 [pydantic]\n",
      "   ------------------------- -------------- 35/56 [pydantic]\n",
      "   ------------------------- -------------- 35/56 [pydantic]\n",
      "   ------------------------- -------------- 35/56 [pydantic]\n",
      "   -------------------------- ------------- 37/56 [jinja2]\n",
      "   -------------------------- ------------- 37/56 [jinja2]\n",
      "   --------------------------- ------------ 38/56 [httpcore]\n",
      "   --------------------------- ------------ 39/56 [h2]\n",
      "   ---------------------------- ----------- 40/56 [anyio]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ----------------------------- ---------- 41/56 [torch]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 42/56 [scikit-learn]\n",
      "   ------------------------------ --------- 43/56 [requests-toolbelt]\n",
      "   ------------------------------ --------- 43/56 [requests-toolbelt]\n",
      "   ------------------------------ --------- 43/56 [requests-toolbelt]\n",
      "   ------------------------------ --------- 43/56 [requests-toolbelt]\n",
      "   ------------------------------- -------- 44/56 [huggingface-hub]\n",
      "   ------------------------------- -------- 44/56 [huggingface-hub]\n",
      "   ------------------------------- -------- 44/56 [huggingface-hub]\n",
      "   ------------------------------- -------- 44/56 [huggingface-hub]\n",
      "   ------------------------------- -------- 44/56 [huggingface-hub]\n",
      "   ------------------------------- -------- 44/56 [huggingface-hub]\n",
      "   ------------------------------- -------- 44/56 [huggingface-hub]\n",
      "   ------------------------------- -------- 44/56 [huggingface-hub]\n",
      "   ------------------------------- -------- 44/56 [huggingface-hub]\n",
      "   ------------------------------- -------- 44/56 [huggingface-hub]\n",
      "   ------------------------------- -------- 44/56 [huggingface-hub]\n",
      "   ------------------------------- -------- 44/56 [huggingface-hub]\n",
      "   ------------------------------- -------- 44/56 [huggingface-hub]\n",
      "   ------------------------------- -------- 44/56 [huggingface-hub]\n",
      "   ------------------------------- -------- 44/56 [huggingface-hub]\n",
      "   -------------------------------- ------- 45/56 [httpx]\n",
      "   -------------------------------- ------- 45/56 [httpx]\n",
      "   -------------------------------- ------- 46/56 [tokenizers]\n",
      "   -------------------------------- ------- 46/56 [tokenizers]\n",
      "   --------------------------------- ------ 47/56 [langsmith]\n",
      "   --------------------------------- ------ 47/56 [langsmith]\n",
      "   --------------------------------- ------ 47/56 [langsmith]\n",
      "   --------------------------------- ------ 47/56 [langsmith]\n",
      "   --------------------------------- ------ 47/56 [langsmith]\n",
      "   ---------------------------------- ----- 48/56 [langgraph-sdk]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 49/56 [transformers]\n",
      "   ----------------------------------- ---- 50/56 [qdrant-client]\n",
      "   ----------------------------------- ---- 50/56 [qdrant-client]\n",
      "   ----------------------------------- ---- 50/56 [qdrant-client]\n",
      "   ----------------------------------- ---- 50/56 [qdrant-client]\n",
      "   ------------------------------------ --- 51/56 [langchain-core]\n",
      "   ------------------------------------ --- 51/56 [langchain-core]\n",
      "   ------------------------------------ --- 51/56 [langchain-core]\n",
      "   ------------------------------------ --- 51/56 [langchain-core]\n",
      "   ------------------------------------ --- 51/56 [langchain-core]\n",
      "   ------------------------------------ --- 51/56 [langchain-core]\n",
      "   ------------------------------------- -- 52/56 [sentence-transformers]\n",
      "   ------------------------------------- -- 52/56 [sentence-transformers]\n",
      "   ------------------------------------- -- 52/56 [sentence-transformers]\n",
      "   ------------------------------------- -- 52/56 [sentence-transformers]\n",
      "   ------------------------------------- -- 52/56 [sentence-transformers]\n",
      "   ------------------------------------- -- 52/56 [sentence-transformers]\n",
      "   ------------------------------------- -- 52/56 [sentence-transformers]\n",
      "   ------------------------------------- -- 52/56 [sentence-transformers]\n",
      "   ------------------------------------- -- 52/56 [sentence-transformers]\n",
      "   ------------------------------------- -- 52/56 [sentence-transformers]\n",
      "   ------------------------------------- -- 53/56 [langgraph-checkpoint]\n",
      "   ---------------------------------------  55/56 [langgraph]\n",
      "   ---------------------------------------  55/56 [langgraph]\n",
      "   ---------------------------------------  55/56 [langgraph]\n",
      "   ---------------------------------------  55/56 [langgraph]\n",
      "   ---------------------------------------- 56/56 [langgraph]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.3 annotated-types-0.7.0 anyio-4.12.0 certifi-2025.11.12 charset_normalizer-3.4.4 filelock-3.20.1 fsspec-2025.12.0 grpcio-1.76.0 h11-0.16.0 h2-4.3.0 hpack-4.1.0 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.36.0 hyperframe-6.1.0 idna-3.11 jinja2-3.1.6 joblib-1.5.3 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-1.2.5 langgraph-1.0.5 langgraph-checkpoint-3.0.1 langgraph-prebuilt-1.0.5 langgraph-sdk-0.3.1 langsmith-0.5.0 mpmath-1.3.0 networkx-3.6.1 numpy-2.4.0 orjson-3.11.5 ormsgpack-1.12.1 portalocker-3.2.0 protobuf-6.33.2 pydantic-2.12.5 pydantic-core-2.41.5 pyyaml-6.0.3 qdrant-client-1.16.2 regex-2025.11.3 requests-2.32.5 requests-toolbelt-1.0.0 safetensors-0.7.0 scikit-learn-1.8.0 scipy-1.16.3 sentence-transformers-5.2.0 sympy-1.14.0 tenacity-9.1.2 threadpoolctl-3.6.0 tokenizers-0.22.1 torch-2.9.1 tqdm-4.67.1 transformers-4.57.3 typing-inspection-0.4.2 urllib3-2.6.2 uuid-utils-0.12.0 xxhash-3.6.0 zstandard-0.25.0\n"
     ]
    }
   ],
   "source": [
    "!pip install qdrant-client pymongo sentence-transformers langgraph torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f866a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sashi\\anaconda3\\envs\\layered\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import asyncio\n",
    "from datetime import datetime, timedelta\n",
    "from uuid import uuid4\n",
    "\n",
    "# =============================================================================\n",
    "# IMPORTS\n",
    "# =============================================================================\n",
    "\n",
    "import redis\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams, PointStruct, Filter, FieldCondition, MatchValue\n",
    "from pymongo import MongoClient\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# LangGraph imports\n",
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "from operator import add\n",
    "\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "REDIS_URL = \"redis://localhost:6379\"\n",
    "QDRANT_URL = \"http://localhost:6333\"\n",
    "MONGODB_URL = \"mongodb://localhost:27017\"\n",
    "\n",
    "# Initialize clients\n",
    "redis_client = redis.from_url(REDIS_URL, decode_responses=True)\n",
    "qdrant_client = QdrantClient(url=QDRANT_URL)\n",
    "mongo_client = MongoClient(MONGODB_URL)\n",
    "mongo_db = mongo_client[\"agent_memory\"]\n",
    "\n",
    "# Initialize embedding model (small model for demo)\n",
    "print(\"Loading embedding model...\")\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "EMBEDDING_DIM = 384  # Dimension for all-MiniLM-L6-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "048fe271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def working_memory_set(session_id: str, key: str, value: dict, ttl: int = 300):\n",
    "    \"\"\"\n",
    "    Store something in working memory.\n",
    "    \n",
    "    Args:\n",
    "        session_id: Unique session identifier\n",
    "        key: What we're storing (e.g., \"current_goal\", \"user_intent\")\n",
    "        value: The data to store\n",
    "        ttl: Time-to-live in seconds (default 5 minutes)\n",
    "    \"\"\"\n",
    "    redis_key = f\"wm:{session_id}:{key}\"\n",
    "    redis_client.setex(redis_key, ttl, json.dumps(value))\n",
    "\n",
    "\n",
    "def working_memory_get(session_id: str, key: str) -> dict | None:\n",
    "    \"\"\"Retrieve something from working memory.\"\"\"\n",
    "    redis_key = f\"wm:{session_id}:{key}\"\n",
    "    data = redis_client.get(redis_key)\n",
    "    return json.loads(data) if data else None\n",
    "\n",
    "\n",
    "def working_memory_add_observation(session_id: str, observation: dict, max_items: int = 10):\n",
    "    \"\"\"\n",
    "    Add an observation to the observation stream.\n",
    "    Uses a Redis list to maintain ordered observations.\n",
    "    \"\"\"\n",
    "    redis_key = f\"wm:{session_id}:observations\"\n",
    "    observation[\"timestamp\"] = datetime.utcnow().isoformat()\n",
    "    \n",
    "    redis_client.lpush(redis_key, json.dumps(observation))\n",
    "    redis_client.ltrim(redis_key, 0, max_items - 1)  # Keep only recent items\n",
    "    redis_client.expire(redis_key, 600)  # Expire after 10 minutes\n",
    "\n",
    "\n",
    "def working_memory_get_observations(session_id: str, limit: int = 5) -> list:\n",
    "    \"\"\"Get recent observations.\"\"\"\n",
    "    redis_key = f\"wm:{session_id}:observations\"\n",
    "    items = redis_client.lrange(redis_key, 0, limit - 1)\n",
    "    return [json.loads(item) for item in items]\n",
    "\n",
    "\n",
    "def working_memory_get_full_context(session_id: str) -> dict:\n",
    "    \"\"\"Get all working memory for a session.\"\"\"\n",
    "    context = {}\n",
    "    \n",
    "    # Get all keys for this session\n",
    "    pattern = f\"wm:{session_id}:*\"\n",
    "    for key in redis_client.scan_iter(match=pattern):\n",
    "        short_key = key.split(\":\")[-1]\n",
    "        if short_key == \"observations\":\n",
    "            context[\"observations\"] = working_memory_get_observations(session_id)\n",
    "        else:\n",
    "            context[short_key] = working_memory_get(session_id, short_key)\n",
    "    \n",
    "    return context\n",
    "\n",
    "\n",
    "def demo_working_memory():\n",
    "    \"\"\"Demonstrate working memory operations.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìù WORKING MEMORY (Redis)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    session_id = f\"demo_{uuid4().hex[:8]}\"\n",
    "    \n",
    "    # Set current goal\n",
    "    working_memory_set(session_id, \"current_goal\", {\n",
    "        \"goal\": \"Help user analyze sales data\",\n",
    "        \"priority\": \"high\"\n",
    "    })\n",
    "    print(\"‚úì Set current goal\")\n",
    "    \n",
    "    # Set user intent\n",
    "    working_memory_set(session_id, \"user_intent\", {\n",
    "        \"intent\": \"data_analysis\",\n",
    "        \"confidence\": 0.9\n",
    "    })\n",
    "    print(\"‚úì Set user intent\")\n",
    "    \n",
    "    # Add some observations\n",
    "    working_memory_add_observation(session_id, {\"type\": \"user_upload\", \"file\": \"sales.csv\"})\n",
    "    working_memory_add_observation(session_id, {\"type\": \"user_question\", \"text\": \"Show me trends\"})\n",
    "    print(\"‚úì Added observations\")\n",
    "    \n",
    "    # Retrieve everything\n",
    "    context = working_memory_get_full_context(session_id)\n",
    "    print(f\"\\nüìã Full Working Memory Context:\")\n",
    "    print(json.dumps(context, indent=2))\n",
    "    \n",
    "    # Show TTL\n",
    "    ttl = redis_client.ttl(f\"wm:{session_id}:current_goal\")\n",
    "    print(f\"\\n‚è∞ TTL remaining: {ttl} seconds (auto-expires!)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae66ebca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìù WORKING MEMORY (Redis)\n",
      "============================================================\n",
      "‚úì Set current goal\n",
      "‚úì Set user intent\n",
      "‚úì Added observations\n",
      "\n",
      "üìã Full Working Memory Context:\n",
      "{\n",
      "  \"observations\": [\n",
      "    {\n",
      "      \"type\": \"user_question\",\n",
      "      \"text\": \"Show me trends\",\n",
      "      \"timestamp\": \"2025-12-23T00:52:35.329675\"\n",
      "    },\n",
      "    {\n",
      "      \"type\": \"user_upload\",\n",
      "      \"file\": \"sales.csv\",\n",
      "      \"timestamp\": \"2025-12-23T00:52:35.318648\"\n",
      "    }\n",
      "  ],\n",
      "  \"user_intent\": {\n",
      "    \"intent\": \"data_analysis\",\n",
      "    \"confidence\": 0.9\n",
      "  },\n",
      "  \"current_goal\": {\n",
      "    \"goal\": \"Help user analyze sales data\",\n",
      "    \"priority\": \"high\"\n",
      "  }\n",
      "}\n",
      "\n",
      "‚è∞ TTL remaining: 300 seconds (auto-expires!)\n"
     ]
    }
   ],
   "source": [
    "demo_working_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82d4bd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_episodic_collection():\n",
    "    \"\"\"Create the episodic memory collection if it doesn't exist.\"\"\"\n",
    "    collections = [c.name for c in qdrant_client.get_collections().collections]\n",
    "    \n",
    "    if \"episodic_memory\" not in collections:\n",
    "        qdrant_client.create_collection(\n",
    "            collection_name=\"episodic_memory\",\n",
    "            vectors_config=VectorParams(size=EMBEDDING_DIM, distance=Distance.COSINE)\n",
    "        )\n",
    "        print(\"‚úì Created episodic_memory collection\")\n",
    "\n",
    "\n",
    "def episodic_memory_store(user_id: str, content: str, summary: str, metadata: dict = None):\n",
    "    \"\"\"\n",
    "    Store an episode (experience/interaction).\n",
    "    \n",
    "    Args:\n",
    "        user_id: Who this memory belongs to\n",
    "        content: Full content of the interaction\n",
    "        summary: Brief summary for context\n",
    "        metadata: Additional info (topics, sentiment, etc.)\n",
    "    \"\"\"\n",
    "    # Generate embedding from content\n",
    "    embedding = embedder.encode(f\"{summary} {content}\").tolist()\n",
    "    \n",
    "    # Create unique ID\n",
    "    point_id = uuid4().hex\n",
    "    \n",
    "    # Build payload\n",
    "    payload = {\n",
    "        \"user_id\": user_id,\n",
    "        \"content\": content,\n",
    "        \"summary\": summary,\n",
    "        \"timestamp\": datetime.utcnow().isoformat(),\n",
    "        \"episode_id\": point_id,\n",
    "        **(metadata or {})\n",
    "    }\n",
    "    \n",
    "    # Store in Qdrant\n",
    "    qdrant_client.upsert(\n",
    "        collection_name=\"episodic_memory\",\n",
    "        points=[PointStruct(id=point_id, vector=embedding, payload=payload)]\n",
    "    )\n",
    "    \n",
    "    return point_id\n",
    "\n",
    "\n",
    "def episodic_memory_search(query: str, user_id: str = None, limit: int = 5) -> list:\n",
    "    \"\"\"\n",
    "    Search episodic memory by semantic similarity.\n",
    "    \n",
    "    Args:\n",
    "        query: What to search for\n",
    "        user_id: Optional filter by user\n",
    "        limit: Max results\n",
    "    \n",
    "    Returns:\n",
    "        List of relevant episodes with similarity scores\n",
    "    \"\"\"\n",
    "    # Generate query embedding\n",
    "    query_embedding = embedder.encode(query).tolist()\n",
    "    \n",
    "    # Build filter if user_id provided\n",
    "    search_filter = None\n",
    "    if user_id:\n",
    "        search_filter = Filter(\n",
    "            must=[FieldCondition(key=\"user_id\", match=MatchValue(value=user_id))]\n",
    "        )\n",
    "    \n",
    "    # Search\n",
    "    results = qdrant_client.query_points(\n",
    "        collection_name=\"episodic_memory\",\n",
    "        query=query_embedding,\n",
    "        query_filter=search_filter,\n",
    "        limit=limit\n",
    "    )\n",
    "    l = [i for i in results]\n",
    "    print('length', len(l))\n",
    "    for r in results:\n",
    "        print(len(r[1]))\n",
    "    return [\n",
    "        {\n",
    "            \"content\": r[1][0].payload[\"content\"],\n",
    "            \"summary\": r[1][0].payload[\"summary\"],\n",
    "            \"timestamp\": r[1][0].payload[\"timestamp\"],\n",
    "            \"score\": r[1][0].score,\n",
    "            **{k: v for k, v in r[1][0].payload.items() if k not in [\"content\", \"summary\", \"timestamp\", \"user_id\"]}\n",
    "        }\n",
    "        for r in results\n",
    "    ]\n",
    "\n",
    "\n",
    "def demo_episodic_memory():\n",
    "    \"\"\"Demonstrate episodic memory operations.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üé¨ EPISODIC MEMORY (Qdrant)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    setup_episodic_collection()\n",
    "    user_id = f\"user_{uuid4().hex[:8]}\"\n",
    "    \n",
    "    # Store some episodes\n",
    "    episodes = [\n",
    "        (\"We discussed Python best practices for data processing. User mentioned they prefer pandas over polars.\",\n",
    "         \"Python data processing discussion\",\n",
    "         {\"topics\": [\"python\", \"pandas\", \"data\"]}),\n",
    "        \n",
    "        (\"User asked about machine learning model deployment. Recommended using FastAPI with Docker.\",\n",
    "         \"ML deployment advice\",\n",
    "         {\"topics\": [\"ml\", \"deployment\", \"docker\"]}),\n",
    "        \n",
    "        (\"Helped debug a SQL query performance issue. The problem was missing indexes on join columns.\",\n",
    "         \"SQL debugging session\",\n",
    "         {\"topics\": [\"sql\", \"performance\", \"debugging\"]}),\n",
    "        \n",
    "        (\"User shared their project goals: build a recommendation system for e-commerce.\",\n",
    "         \"Project planning discussion\",\n",
    "         {\"topics\": [\"recommendation\", \"ecommerce\", \"planning\"]}),\n",
    "        (\"User shared their Movie interest: User mentioned they like action and comedy movies.\",\n",
    "         \"Movie interest discussion\",\n",
    "         {\"topics\": [\"movies\", \"action\", \"comedy\"]})\n",
    "    ]\n",
    "    \n",
    "    for content, summary, metadata in episodes:\n",
    "        episodic_memory_store(user_id, content, summary, metadata)\n",
    "    print(f\"‚úì Stored {len(episodes)} episodes\")\n",
    "    \n",
    "    # Search for relevant episodes\n",
    "    print(\"\\nüîç Searching for 'Python best practices for data processing':\")\n",
    "    results = episodic_memory_search(\"recommend me a movie\", user_id, limit=3)\n",
    "    \n",
    "    for i, r in enumerate(results, 1):\n",
    "        print(f\"\\n   {i}. [{r['score']:.2f}] {r['summary']}\")\n",
    "        print(f\"      Topics: {r.get('topics', [])}\")\n",
    "        print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "179b63da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üé¨ EPISODIC MEMORY (Qdrant)\n",
      "============================================================\n",
      "‚úì Created episodic_memory collection\n",
      "‚úì Stored 5 episodes\n",
      "\n",
      "üîç Searching for 'Python best practices for data processing':\n",
      "length 1\n",
      "3\n",
      "\n",
      "   1. [0.40] Movie interest discussion\n",
      "      Topics: ['movies', 'action', 'comedy']\n",
      "{'content': 'User shared their Movie interest: User mentioned they like action and comedy movies.', 'summary': 'Movie interest discussion', 'timestamp': '2025-12-23T00:52:47.984691', 'score': 0.4023379, 'episode_id': '9b5d9c3b8e124517aaa27ae1420ac183', 'topics': ['movies', 'action', 'comedy']}\n"
     ]
    }
   ],
   "source": [
    "demo_episodic_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a27b5954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_semantic_collection():\n",
    "    \"\"\"Create the semantic memory collection if it doesn't exist.\"\"\"\n",
    "    collections = [c.name for c in qdrant_client.get_collections().collections]\n",
    "    \n",
    "    if \"semantic_memory\" not in collections:\n",
    "        qdrant_client.create_collection(\n",
    "            collection_name=\"semantic_memory\",\n",
    "            vectors_config=VectorParams(size=EMBEDDING_DIM, distance=Distance.COSINE)\n",
    "        )\n",
    "        print(\"‚úì Created semantic_memory collection\")\n",
    "\n",
    "\n",
    "def semantic_memory_store(\n",
    "    user_id: str,\n",
    "    knowledge: str,\n",
    "    knowledge_type: str = \"fact\",  # fact, preference, skill, relationship\n",
    "    confidence: float = 0.8,\n",
    "    metadata: dict = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Store a piece of knowledge.\n",
    "    \n",
    "    Args:\n",
    "        user_id: Who this knowledge is about\n",
    "        knowledge: The factual statement\n",
    "        knowledge_type: Type of knowledge (fact/preference/skill/relationship)\n",
    "        confidence: How confident we are (0-1)\n",
    "        metadata: Additional context\n",
    "    \"\"\"\n",
    "    embedding = embedder.encode(knowledge).tolist()\n",
    "    point_id = uuid4().hex\n",
    "    \n",
    "    payload = {\n",
    "        \"user_id\": user_id,\n",
    "        \"knowledge\": knowledge,\n",
    "        \"knowledge_type\": knowledge_type,\n",
    "        \"confidence\": confidence,\n",
    "        \"created_at\": datetime.utcnow().isoformat(),\n",
    "        \"memory_id\": point_id,\n",
    "        **(metadata or {})\n",
    "    }\n",
    "    \n",
    "    qdrant_client.upsert(\n",
    "        collection_name=\"semantic_memory\",\n",
    "        points=[PointStruct(id=point_id, vector=embedding, payload=payload)]\n",
    "    )\n",
    "    \n",
    "    return point_id\n",
    "\n",
    "\n",
    "def semantic_memory_search(\n",
    "    query: str,\n",
    "    user_id: str = None,\n",
    "    knowledge_type: str = None,\n",
    "    min_confidence: float = 0.0,\n",
    "    limit: int = 5\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    Search semantic memory.\n",
    "    \n",
    "    Can filter by user, knowledge type, and minimum confidence.\n",
    "    \"\"\"\n",
    "    query_embedding = embedder.encode(query).tolist()\n",
    "    \n",
    "    # Build filters\n",
    "    conditions = []\n",
    "    if user_id:\n",
    "        conditions.append(FieldCondition(key=\"user_id\", match=MatchValue(value=user_id)))\n",
    "    if knowledge_type:\n",
    "        conditions.append(FieldCondition(key=\"knowledge_type\", match=MatchValue(value=knowledge_type)))\n",
    "    \n",
    "    search_filter = Filter(must=conditions) if conditions else None\n",
    "\n",
    "    results = qdrant_client.query_points(\n",
    "        collection_name=\"semantic_memory\",\n",
    "        query=query_embedding,\n",
    "        query_filter=search_filter,\n",
    "        limit=limit\n",
    "    )\n",
    "    \n",
    "    # Filter by confidence after retrieval\n",
    "    for r in results:\n",
    "        print('query_result =', r)\n",
    "    return [\n",
    "        {\n",
    "            \"knowledge\": r[1][0].payload[\"knowledge\"],\n",
    "            \"type\": r[1][0].payload[\"knowledge_type\"],\n",
    "            \"confidence\": r[1][0].payload[\"confidence\"],\n",
    "            \"score\": r[1][0].score\n",
    "        }\n",
    "        for r in results\n",
    "        if r[1][0].payload[\"confidence\"] >= min_confidence\n",
    "    ]\n",
    "\n",
    "\n",
    "def demo_semantic_memory():\n",
    "    \"\"\"Demonstrate semantic memory operations.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üß† SEMANTIC MEMORY (Qdrant)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    setup_semantic_collection()\n",
    "    user_id = f\"user_{uuid4().hex[:8]}\"\n",
    "    \n",
    "    # Store various types of knowledge\n",
    "    knowledge_items = [\n",
    "        (\"User prefers Python over JavaScript for backend work\", \"preference\", 0.9),\n",
    "        (\"User works at a fintech startup as a data engineer\", \"fact\", 0.95),\n",
    "        (\"User is experienced with PostgreSQL and Redis\", \"skill\", 0.85),\n",
    "        (\"User's team lead is named Sarah\", \"relationship\", 0.8),\n",
    "        (\"User prefers morning meetings over afternoon ones\", \"preference\", 0.7),\n",
    "        (\"User is learning Rust in their spare time\", \"fact\", 0.75),\n",
    "    ]\n",
    "    \n",
    "    for knowledge, ktype, confidence in knowledge_items:\n",
    "        semantic_memory_store(user_id, knowledge, ktype, confidence)\n",
    "    print(f\"‚úì Stored {len(knowledge_items)} knowledge items\")\n",
    "    \n",
    "    # Search for preferences\n",
    "    print(\"\\nüîç Searching for 'programming preferences':\")\n",
    "    results = semantic_memory_search(\n",
    "        \"programming language preferences\",\n",
    "        user_id=user_id,\n",
    "        knowledge_type=\"preference\",\n",
    "        limit=3\n",
    "    )\n",
    "    \n",
    "    for r in results:\n",
    "        print(f\"   [{r['confidence']:.0%}] {r['knowledge']}\")\n",
    "    \n",
    "    # Search for skills\n",
    "    print(\"\\nüîç Searching for 'database skills':\")\n",
    "    results = semantic_memory_search(\n",
    "        \"database experience\",\n",
    "        user_id=user_id,\n",
    "        knowledge_type=\"skill\",\n",
    "        limit=3\n",
    "    )\n",
    "    \n",
    "    for r in results:\n",
    "        print(f\"   [{r['confidence']:.0%}] {r['knowledge']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95e536c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üß† SEMANTIC MEMORY (Qdrant)\n",
      "============================================================\n",
      "‚úì Created semantic_memory collection\n",
      "‚úì Stored 6 knowledge items\n",
      "\n",
      "üîç Searching for 'programming preferences':\n",
      "query_result = ('points', [ScoredPoint(id='db4a83b7-55de-4024-ac18-be4f6328173d', version=1, score=0.39543617, payload={'user_id': 'user_7ff3f921', 'knowledge': 'User prefers Python over JavaScript for backend work', 'knowledge_type': 'preference', 'confidence': 0.9, 'created_at': '2025-12-23T00:53:09.158130', 'memory_id': 'db4a83b755de4024ac18be4f6328173d'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id='c0b28d3f-58f1-49e7-ad6d-cae69511e037', version=5, score=0.13748819, payload={'user_id': 'user_7ff3f921', 'knowledge': 'User prefers morning meetings over afternoon ones', 'knowledge_type': 'preference', 'confidence': 0.7, 'created_at': '2025-12-23T00:53:09.343981', 'memory_id': 'c0b28d3f58f149e7ad6dcae69511e037'}, vector=None, shard_key=None, order_value=None)])\n",
      "   [90%] User prefers Python over JavaScript for backend work\n",
      "\n",
      "üîç Searching for 'database skills':\n",
      "query_result = ('points', [ScoredPoint(id='2c0f2998-0124-4549-ab85-254318bb19fc', version=3, score=0.3207181, payload={'user_id': 'user_7ff3f921', 'knowledge': 'User is experienced with PostgreSQL and Redis', 'knowledge_type': 'skill', 'confidence': 0.85, 'created_at': '2025-12-23T00:53:09.271249', 'memory_id': '2c0f299801244549ab85254318bb19fc'}, vector=None, shard_key=None, order_value=None)])\n",
      "   [85%] User is experienced with PostgreSQL and Redis\n"
     ]
    }
   ],
   "source": [
    "demo_semantic_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec6e8671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procedural_memory_store(\n",
    "    user_id: str,\n",
    "    name: str,\n",
    "    tool_name: str,\n",
    "    steps: list,\n",
    "    trigger_patterns: list = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Store a procedure (learned skill).\n",
    "    \n",
    "    Args:\n",
    "        user_id: Who learned this\n",
    "        name: Name of the procedure\n",
    "        tool_name: What tool this is for\n",
    "        steps: List of steps to execute\n",
    "        trigger_patterns: When to use this procedure\n",
    "    \"\"\"\n",
    "    procedure = {\n",
    "        \"procedure_id\": uuid4().hex,\n",
    "        \"user_id\": user_id,\n",
    "        \"name\": name,\n",
    "        \"tool_name\": tool_name,\n",
    "        \"steps\": steps,\n",
    "        \"trigger_patterns\": trigger_patterns or [],\n",
    "        \"created_at\": datetime.utcnow(),\n",
    "        \"total_executions\": 0,\n",
    "        \"successful_executions\": 0,\n",
    "        \"success_rate\": 0.0\n",
    "    }\n",
    "    \n",
    "    mongo_db.procedures.insert_one(procedure)\n",
    "    return procedure[\"procedure_id\"]\n",
    "\n",
    "\n",
    "def procedural_memory_record_execution(\n",
    "    procedure_id: str,\n",
    "    success: bool,\n",
    "    duration_ms: int,\n",
    "    error: str = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Record an execution of a procedure.\n",
    "    Updates success rate automatically.\n",
    "    \"\"\"\n",
    "    # Record the trace\n",
    "    trace = {\n",
    "        \"trace_id\": uuid4().hex,\n",
    "        \"procedure_id\": procedure_id,\n",
    "        \"timestamp\": datetime.utcnow(),\n",
    "        \"success\": success,\n",
    "        \"duration_ms\": duration_ms,\n",
    "        \"error\": error\n",
    "    }\n",
    "    mongo_db.traces.insert_one(trace)\n",
    "    \n",
    "    # Update procedure stats\n",
    "    procedure = mongo_db.procedures.find_one({\"procedure_id\": procedure_id})\n",
    "    if procedure:\n",
    "        total = procedure[\"total_executions\"] + 1\n",
    "        successful = procedure[\"successful_executions\"] + (1 if success else 0)\n",
    "        \n",
    "        mongo_db.procedures.update_one(\n",
    "            {\"procedure_id\": procedure_id},\n",
    "            {\"$set\": {\n",
    "                \"total_executions\": total,\n",
    "                \"successful_executions\": successful,\n",
    "                \"success_rate\": successful / total\n",
    "            }}\n",
    "        )\n",
    "\n",
    "\n",
    "def procedural_memory_find_best(tool_name: str, user_id: str = None) -> dict | None:\n",
    "    \"\"\"\n",
    "    Find the best procedure for a tool based on success rate.\n",
    "    \"\"\"\n",
    "    query = {\"tool_name\": tool_name}\n",
    "    if user_id:\n",
    "        query[\"user_id\"] = user_id\n",
    "    \n",
    "    procedures = list(mongo_db.procedures.find(query).sort(\"success_rate\", -1).limit(1))\n",
    "    return procedures[0] if procedures else None\n",
    "\n",
    "\n",
    "def procedural_memory_get_stats(procedure_id: str) -> dict:\n",
    "    \"\"\"Get statistics for a procedure.\"\"\"\n",
    "    procedure = mongo_db.procedures.find_one({\"procedure_id\": procedure_id})\n",
    "    if not procedure:\n",
    "        return {}\n",
    "    \n",
    "    # Get recent traces\n",
    "    recent_traces = list(\n",
    "        mongo_db.traces.find({\"procedure_id\": procedure_id})\n",
    "        .sort(\"timestamp\", -1)\n",
    "        .limit(10)\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"name\": procedure[\"name\"],\n",
    "        \"total_executions\": procedure[\"total_executions\"],\n",
    "        \"success_rate\": procedure[\"success_rate\"],\n",
    "        \"recent_outcomes\": [t[\"success\"] for t in recent_traces]\n",
    "    }\n",
    "\n",
    "\n",
    "def demo_procedural_memory():\n",
    "    \"\"\"Demonstrate procedural memory operations.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"‚öôÔ∏è PROCEDURAL MEMORY (MongoDB)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    user_id = f\"user_{uuid4().hex[:8]}\"\n",
    "    \n",
    "    # Create a procedure\n",
    "    procedure_id = procedural_memory_store(\n",
    "        user_id=user_id,\n",
    "        name=\"CSV Data Analysis\",\n",
    "        tool_name=\"data_analyzer\",\n",
    "        steps=[\n",
    "            {\"action\": \"load_csv\", \"params\": {\"encoding\": \"utf-8\"}},\n",
    "            {\"action\": \"check_missing_values\", \"params\": {}},\n",
    "            {\"action\": \"generate_summary_stats\", \"params\": {\"columns\": \"all\"}},\n",
    "            {\"action\": \"create_visualizations\", \"params\": {\"type\": \"auto\"}}\n",
    "        ],\n",
    "        trigger_patterns=[\"analyze csv\", \"data analysis\", \"explore data\"]\n",
    "    )\n",
    "    print(f\"‚úì Created procedure: CSV Data Analysis\")\n",
    "    \n",
    "    # Simulate some executions\n",
    "    executions = [\n",
    "        (True, 150),\n",
    "        (True, 180),\n",
    "        (True, 165),\n",
    "        (False, 200),  # One failure\n",
    "        (True, 145),\n",
    "        (True, 170),\n",
    "    ]\n",
    "    \n",
    "    for success, duration in executions:\n",
    "        procedural_memory_record_execution(procedure_id, success, duration)\n",
    "    print(f\"‚úì Recorded {len(executions)} executions\")\n",
    "    \n",
    "    # Get stats\n",
    "    stats = procedural_memory_get_stats(procedure_id)\n",
    "    print(f\"\\nüìä Procedure Statistics:\")\n",
    "    print(f\"   Name: {stats['name']}\")\n",
    "    print(f\"   Total Executions: {stats['total_executions']}\")\n",
    "    print(f\"   Success Rate: {stats['success_rate']:.0%}\")\n",
    "    print(f\"   Recent Outcomes: {['‚úì' if s else '‚úó' for s in stats['recent_outcomes']]}\")\n",
    "    \n",
    "    # Find best procedure for tool\n",
    "    best = procedural_memory_find_best(\"data_analyzer\", user_id)\n",
    "    if best:\n",
    "        print(f\"\\nüèÜ Best procedure for 'data_analyzer': {best['name']} ({best['success_rate']:.0%} success)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d0841eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "‚öôÔ∏è PROCEDURAL MEMORY (MongoDB)\n",
      "============================================================\n",
      "‚úì Created procedure: CSV Data Analysis\n",
      "‚úì Recorded 6 executions\n",
      "\n",
      "üìä Procedure Statistics:\n",
      "   Name: CSV Data Analysis\n",
      "   Total Executions: 6\n",
      "   Success Rate: 83%\n",
      "   Recent Outcomes: ['‚úì', '‚úì', '‚úó', '‚úì', '‚úì', '‚úì']\n",
      "\n",
      "üèÜ Best procedure for 'data_analyzer': CSV Data Analysis (83% success)\n"
     ]
    }
   ],
   "source": [
    "demo_procedural_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d3b0cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    \"\"\"State that flows through our agent graph.\"\"\"\n",
    "    user_message: str\n",
    "    user_id: str\n",
    "    session_id: str\n",
    "    working_memory: dict\n",
    "    episodic_context: list\n",
    "    semantic_context: list\n",
    "    procedural_context: list\n",
    "    response: str\n",
    "\n",
    "\n",
    "def node_load_working_memory(state: AgentState) -> dict:\n",
    "    \"\"\"Load current working memory.\"\"\"\n",
    "    context = working_memory_get_full_context(state[\"session_id\"])\n",
    "    return {\"working_memory\": context}\n",
    "\n",
    "\n",
    "def node_retrieve_episodic(state: AgentState) -> dict:\n",
    "    \"\"\"Retrieve relevant past episodes.\"\"\"\n",
    "    results = episodic_memory_search(\n",
    "        state[\"user_message\"],\n",
    "        user_id=state[\"user_id\"],\n",
    "        limit=3\n",
    "    )\n",
    "    return {\"episodic_context\": results}\n",
    "\n",
    "\n",
    "def node_retrieve_semantic(state: AgentState) -> dict:\n",
    "    \"\"\"Retrieve relevant knowledge.\"\"\"\n",
    "    results = semantic_memory_search(\n",
    "        state[\"user_message\"],\n",
    "        user_id=state[\"user_id\"],\n",
    "        min_confidence=0.5,\n",
    "        limit=3\n",
    "    )\n",
    "    return {\"semantic_context\": results}\n",
    "\n",
    "\n",
    "def node_retrieve_procedural(state: AgentState) -> dict:\n",
    "    \"\"\"Find relevant procedures.\"\"\"\n",
    "    # Simple keyword matching for demo\n",
    "    procedures = list(mongo_db.procedures.find({\"user_id\": state[\"user_id\"]}).limit(2))\n",
    "    return {\"procedural_context\": [\n",
    "        {\"name\": p[\"name\"], \"tool\": p[\"tool_name\"], \"success_rate\": p[\"success_rate\"]}\n",
    "        for p in procedures\n",
    "    ]}\n",
    "\n",
    "\n",
    "def node_generate_response(state: AgentState) -> dict:\n",
    "    \"\"\"Generate response based on all memory context.\"\"\"\n",
    "    # In a real system, this would call an LLM\n",
    "    # For demo, we just summarize what we found\n",
    "    \n",
    "    response_parts = [f\"Processing: '{state['user_message']}'\"]\n",
    "    \n",
    "    if state[\"working_memory\"]:\n",
    "        response_parts.append(f\"\\nüìù Working Memory: {len(state['working_memory'])} items loaded\")\n",
    "    \n",
    "    if state[\"episodic_context\"]:\n",
    "        response_parts.append(f\"\\nüé¨ Found {len(state['episodic_context'])} relevant past interactions\")\n",
    "        for ep in state[\"episodic_context\"][:2]:\n",
    "            response_parts.append(f\"   - {ep['summary']}\")\n",
    "    \n",
    "    if state[\"semantic_context\"]:\n",
    "        response_parts.append(f\"\\nüß† Found {len(state['semantic_context'])} relevant facts\")\n",
    "        for sm in state[\"semantic_context\"][:2]:\n",
    "            response_parts.append(f\"   - {sm['knowledge']}\")\n",
    "    \n",
    "    if state[\"procedural_context\"]:\n",
    "        response_parts.append(f\"\\n‚öôÔ∏è Found {len(state['procedural_context'])} applicable procedures\")\n",
    "        for pm in state[\"procedural_context\"]:\n",
    "            response_parts.append(f\"   - {pm['name']} ({pm['success_rate']:.0%} success)\")\n",
    "    \n",
    "    return {\"response\": \"\\n\".join(response_parts)}\n",
    "\n",
    "\n",
    "def build_memory_agent():\n",
    "    \"\"\"Build a LangGraph agent with memory retrieval.\"\"\"\n",
    "    workflow = StateGraph(AgentState)\n",
    "    \n",
    "    # Add nodes\n",
    "    workflow.add_node(\"load_working_memory\", node_load_working_memory)\n",
    "    workflow.add_node(\"retrieve_episodic\", node_retrieve_episodic)\n",
    "    workflow.add_node(\"retrieve_semantic\", node_retrieve_semantic)\n",
    "    workflow.add_node(\"retrieve_procedural\", node_retrieve_procedural)\n",
    "    workflow.add_node(\"generate_response\", node_generate_response)\n",
    "    \n",
    "    # Define the flow\n",
    "    workflow.set_entry_point(\"load_working_memory\")\n",
    "    workflow.add_edge(\"load_working_memory\", \"retrieve_episodic\")\n",
    "    workflow.add_edge(\"retrieve_episodic\", \"retrieve_semantic\")\n",
    "    workflow.add_edge(\"retrieve_semantic\", \"retrieve_procedural\")\n",
    "    workflow.add_edge(\"retrieve_procedural\", \"generate_response\")\n",
    "    workflow.add_edge(\"generate_response\", END)\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "\n",
    "def demo_langgraph_integration():\n",
    "    \"\"\"Demonstrate LangGraph memory integration.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üîó LANGGRAPH INTEGRATION\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Setup - reuse data from previous demos\n",
    "    #user_id = f\"user_{uuid4().hex[:8]}\"\n",
    "    user_id = \"user_12345678\"  # Using a fixed user ID for demonstration\n",
    "    #session_id = f\"session_{uuid4().hex[:8]}\"\n",
    "    session_id = \"session_12345678\"  # Using a fixed session ID for demonstration\n",
    "    \n",
    "    # Populate some memory first\n",
    "    print(\"\\nüì¶ Setting up memory...\")\n",
    "    \n",
    "    # Working memory\n",
    "    working_memory_set(session_id, \"current_goal\", {\"goal\": \"Help with data analysis\"})\n",
    "    working_memory_add_observation(session_id, {\"type\": \"greeting\", \"text\": \"User said hello\"})\n",
    "    \n",
    "    # Episodic memory\n",
    "    setup_episodic_collection()\n",
    "    episodic_memory_store(user_id, \n",
    "        \"Helped user set up a Python data pipeline with pandas\",\n",
    "        \"Python data pipeline setup\",\n",
    "        {\"topics\": [\"python\", \"pandas\", \"pipeline\"]}\n",
    "    )\n",
    "    \n",
    "    # Semantic memory\n",
    "    setup_semantic_collection()\n",
    "    semantic_memory_store(user_id, \"User prefers pandas for data manipulation\", \"preference\", 0.9)\n",
    "    semantic_memory_store(user_id, \"User works with CSV files frequently\", \"fact\", 0.85)\n",
    "    \n",
    "    # Procedural memory\n",
    "    procedural_memory_store(\n",
    "        user_id, \"CSV Processing\", \"pandas_tool\",\n",
    "        [{\"action\": \"read_csv\"}, {\"action\": \"clean_data\"}, {\"action\": \"analyze\"}],\n",
    "        [\"process csv\", \"analyze data\"]\n",
    "    )\n",
    "    procedural_memory_record_execution(\n",
    "        mongo_db.procedures.find_one({\"user_id\": user_id})[\"procedure_id\"],\n",
    "        True, 100\n",
    "    )\n",
    "    \n",
    "    print(\"‚úì Memory populated\")\n",
    "    \n",
    "    # Build and run the agent\n",
    "    agent = build_memory_agent()\n",
    "    \n",
    "    initial_state = {\n",
    "        \"user_message\": \"can you recommend me a movie?\",\n",
    "        \"user_id\": user_id,\n",
    "        \"session_id\": session_id,\n",
    "        \"working_memory\": {},\n",
    "        \"episodic_context\": [],\n",
    "        \"semantic_context\": [],\n",
    "        \"procedural_context\": [],\n",
    "        \"response\": \"\"\n",
    "    }\n",
    "\n",
    "    print(\"\\nü§ñ Running memory-aware agent...\")\n",
    "    print(f\"   User: '{initial_state['user_message']}'\")\n",
    "    \n",
    "    # Execute the graph\n",
    "    final_state = agent.invoke(initial_state)\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*40)\n",
    "    print(\"üì§ Agent Response:\")\n",
    "    print(final_state[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f183d4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üîó LANGGRAPH INTEGRATION\n",
      "============================================================\n",
      "\n",
      "üì¶ Setting up memory...\n",
      "‚úì Memory populated\n",
      "\n",
      "ü§ñ Running memory-aware agent...\n",
      "   User: 'can you recommend me a movie?'\n",
      "length 1\n",
      "1\n",
      "query_result = ('points', [ScoredPoint(id='d98ee25a-67fb-457b-bb0d-45fbe7b74131', version=7, score=0.06648329, payload={'user_id': 'user_12345678', 'knowledge': 'User prefers pandas for data manipulation', 'knowledge_type': 'preference', 'confidence': 0.9, 'created_at': '2025-12-23T00:53:39.734401', 'memory_id': 'd98ee25a67fb457bbb0d45fbe7b74131'}, vector=None, shard_key=None, order_value=None), ScoredPoint(id='59f91f6e-d097-4d24-8a4b-f85a2e4018cd', version=8, score=-0.002700436, payload={'user_id': 'user_12345678', 'knowledge': 'User works with CSV files frequently', 'knowledge_type': 'fact', 'confidence': 0.85, 'created_at': '2025-12-23T00:53:39.764841', 'memory_id': '59f91f6ed0974d248a4bf85a2e4018cd'}, vector=None, shard_key=None, order_value=None)])\n",
      "\n",
      "----------------------------------------\n",
      "üì§ Agent Response:\n",
      "Processing: 'can you recommend me a movie?'\n",
      "\n",
      "üìù Working Memory: 2 items loaded\n",
      "\n",
      "üé¨ Found 1 relevant past interactions\n",
      "   - Python data pipeline setup\n",
      "\n",
      "üß† Found 1 relevant facts\n",
      "   - User prefers pandas for data manipulation\n",
      "\n",
      "‚öôÔ∏è Found 1 applicable procedures\n",
      "   - CSV Processing (100% success)\n"
     ]
    }
   ],
   "source": [
    "demo_langgraph_integration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765d445e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "layered",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
